"""
Streamlit ê¸°ë°˜ RAG Assistant ì›¹ UI
ë¬¸ì„œ ì—…ë¡œë“œ ë° ì§ˆì˜ì‘ë‹µ ì¸í„°í˜ì´ìŠ¤
(Serverless RAG Lambda API ì—°ë™ + Local ëª¨ë“œ ë³‘í–‰ ì§€ì›)
"""

import os
import sys
from pathlib import Path
from typing import Dict, Any

import base64
import requests
import streamlit as st
import json

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ë¥¼ ê²½ë¡œì— ì¶”ê°€
# app/web/main.py -> app/web -> app -> í”„ë¡œì íŠ¸ ë£¨íŠ¸
project_root = Path(__file__).resolve().parents[2]
sys.path.insert(0, str(project_root))

# LOCAL ëª¨ë“œ ì„œë¹„ìŠ¤ ë ˆì´ì–´ import
from src.vectorstore.mock_store import MockVectorStore
from src.embeddings.embedder import EmbeddingGenerator
from src.services.ingestion_service import process_document_ingestion
from src.services.rag_service import process_rag_query

# í˜ì´ì§€ ì„¤ì •
st.set_page_config(
    page_title="Serverless RAG Assistant",
    page_icon="ğŸ¤–",
    layout="wide",
)

# Lambda API Base URL (ë°°í¬ëœ API Gateway URL)
API_BASE_URL = "https://pirm3fhtfe.execute-api.ap-southeast-2.amazonaws.com/prod"


def init_session():
    """ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”"""
    if "initialized" not in st.session_state:
        st.session_state["initialized"] = True
        st.session_state["mock_store"] = MockVectorStore()
        st.session_state["embedding_generator"] = EmbeddingGenerator()


init_session()


def render_sidebar() -> Dict[str, Any]:
    """
    ì‚¬ì´ë“œë°” ë Œë”ë§
    
    Returns:
        ì„¤ì • ë”•ì…”ë„ˆë¦¬ (mode, top_k, temperature, max_tokens)
    """
    with st.sidebar:
        st.header("âš™ï¸ ì‹¤í–‰ ì„¤ì •")

        mode = st.radio("ì‹¤í–‰ ëª¨ë“œ", ["LOCAL", "API"], index=1)

        st.markdown("**ğŸ”— í˜„ì¬ API Gateway**")
        st.code(API_BASE_URL, language="bash")

        top_k = st.slider("Top-K", 1, 20, 5)
        temperature = st.slider("Temperature", 0.0, 2.0, 0.0, step=0.1)
        max_tokens = st.number_input("Max Tokens", 100, 3000, 1000, step=100)

    return {
        "mode": mode,
        "top_k": top_k,
        "temperature": temperature,
        "max_tokens": max_tokens,
    }


def render_query_tab(settings: Dict[str, Any]):
    """
    RAG Chat íƒ­ ë Œë”ë§
    
    Args:
        settings: ì‚¬ì´ë“œë°”ì—ì„œ ì„¤ì •í•œ íŒŒë¼ë¯¸í„° ë”•ì…”ë„ˆë¦¬
    """
    st.header("ğŸ’¬ RAG Chat")

    question = st.text_area("ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”", height=140, placeholder="ì˜ˆ: RAGê°€ ë­ì•¼? / ì´ ë¬¸ì„œì˜ í•µì‹¬ë§Œ ìš”ì•½í•´ì¤˜")

    col_submit, col_clear = st.columns([1, 4])
    submit_button = col_submit.button("ì§ˆë¬¸í•˜ê¸°", type="primary")
    clear_button = col_clear.button("ì´ˆê¸°í™”")

    if clear_button:
        st.rerun()

    def query_via_api(query: str) -> Dict[str, Any]:
        """API ëª¨ë“œì—ì„œ ì§ˆì˜ì‘ë‹µ ìš”ì²­"""
        payload = {
            "question": query,
            "top_k": settings["top_k"],
            "temperature": settings["temperature"],
            "max_tokens": settings["max_tokens"],
        }

        res = requests.post(f"{API_BASE_URL}/query", json=payload, timeout=60)
        res.raise_for_status()
        return res.json()

    if submit_button:
        if not question.strip():
            st.warning("ì§ˆë¬¸ì„ ì…ë ¥í•´ì£¼ì„¸ìš”.")
            return

        with st.spinner("RAG ì‹¤í–‰ ì¤‘â€¦"):
            try:
                if settings["mode"] == "LOCAL":
                    result = process_rag_query(
                        query=question,
                        vector_store=st.session_state["mock_store"],
                        embedding_generator=st.session_state["embedding_generator"],
                        top_k=settings["top_k"],
                    )
                else:
                    result = query_via_api(question)

            except requests.exceptions.RequestException as e:
                st.error(
                    "ğŸš¨ API í˜¸ì¶œ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.\n\n"
                    f"- URL: `{API_BASE_URL}/query`\n"
                    f"- ì˜¤ë¥˜: `{e}`\n\n"
                    "API Gateway / Lambda ìƒíƒœë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”."
                )
                return
            except Exception as e:
                st.error(f"ğŸš¨ RAG ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")
                return

        answer = result.get("answer", "")
        sources = result.get("source_documents", []) or []

        st.success(f"âœ… ë‹µë³€ ìƒì„± ì™„ë£Œ (ì°¸ì¡° ë¬¸ì„œ {len(sources)}ê°œ ì‚¬ìš©)")

        st.markdown("### ğŸ“ ë‹µë³€")
        st.write(answer)

        if sources:
            st.markdown("### ğŸ“š ì°¸ì¡° ë¬¸ì„œ")
            for idx, doc in enumerate(sources, 1):
                with st.expander(f"ğŸ“„ ë¬¸ì„œ {idx}"):
                    text = doc.get("text") or doc.get("content") or ""
                    st.write(text)
                    st.json(doc)


def render_documents_tab(settings: Dict[str, Any]):
    """
    ë¬¸ì„œ ì—…ë¡œë“œ/ê´€ë¦¬ íƒ­ ë Œë”ë§
    
    Args:
        settings: ì‚¬ì´ë“œë°”ì—ì„œ ì„¤ì •í•œ íŒŒë¼ë¯¸í„° ë”•ì…”ë„ˆë¦¬
    """
    st.header("ğŸ“š ë¬¸ì„œ ì—…ë¡œë“œ / ê´€ë¦¬")

    uploaded = st.file_uploader("ë¬¸ì„œ ì—…ë¡œë“œ", type=["pdf", "txt", "md"])

    def upload_via_api(uploaded_file):
        """API ëª¨ë“œì—ì„œ ë¬¸ì„œ ì—…ë¡œë“œ ìš”ì²­"""
        file_bytes = uploaded_file.read()
        file_b64 = base64.b64encode(file_bytes).decode()

        payload = {
            "filename": uploaded_file.name,
            "file_b64": file_b64,
        }

        res = requests.post(f"{API_BASE_URL}/upload", json=payload, timeout=60)
        res.raise_for_status()
        return res.json()

    def list_documents_via_api():
        """API ëª¨ë“œì—ì„œ ë¬¸ì„œ ëª©ë¡ ì¡°íšŒ"""
        try:
            res = requests.get(f"{API_BASE_URL}/documents", timeout=30)
            res.raise_for_status()

            # Lambda Proxy í†µí•© ì‹œ bodyëŠ” stringìœ¼ë¡œ ë„˜ì–´ì˜´ â†’ ì§ì ‘ íŒŒì‹± í•„ìš”
            data = res.json()

            # bodyê°€ dictê°€ ì•„ë‹ˆë¼ string í˜•íƒœë¼ë©´ json.loads() ìˆ˜í–‰
            if isinstance(data, dict) and "body" in data and isinstance(data["body"], str):
                data = json.loads(data["body"])

            return data

        except Exception as e:
            st.error(f"ë¬¸ì„œ ëª©ë¡ ì¡°íšŒ ì‹¤íŒ¨: {e}")
            return None

    if uploaded and st.button("ğŸ“¥ ë¬¸ì„œ ì²˜ë¦¬ ì‹œì‘"):
        with st.spinner("ë¬¸ì„œ ë¶„ì„ ì¤‘â€¦"):
            try:
                if settings["mode"] == "LOCAL":
                    info = process_document_ingestion(
                        file_bytes=uploaded.read(),
                        filename=uploaded.name,
                        vector_store=st.session_state["mock_store"],
                        embedding_generator=st.session_state["embedding_generator"],
                    )
                else:
                    info = upload_via_api(uploaded)

            except Exception as e:
                st.error(f"ì˜¤ë¥˜ ë°œìƒ: {e}")
                return

        num_chunks = info.get("num_chunks", 0)
        st.success(f"âœ” ì²˜ë¦¬ ì™„ë£Œ: {num_chunks}ê°œ ì²­í¬ ìƒì„±ë¨")
        st.rerun()

    st.markdown("---")

    if settings["mode"] == "LOCAL":
        docs = st.session_state["mock_store"].get_all_documents()
        st.write(f"ì´ ì²­í¬ ìˆ˜: {len(docs)}")

        grouped = {}
        for d in docs:
            grouped.setdefault(d.document_id, 0)
            grouped[d.document_id] += 1

        for doc_id, count in grouped.items():
            st.write(f"ğŸ“„ {doc_id} â€” {count}ê°œ ì²­í¬")
    else:
        st.subheader("ğŸŒ API ë¬¸ì„œ ëª©ë¡ ì¡°íšŒ")

        docs = list_documents_via_api()

        if docs:
            st.write(f"ì´ ë¬¸ì„œ ìˆ˜: {docs.get('total_documents', 0)}")

            for d in docs.get("documents", []):
                st.write(f"ğŸ“„ {d['document_id']} â€” {d['num_chunks']}ê°œ ì²­í¬")
        else:
            st.info("ë¬¸ì„œ ëª©ë¡ì„ ê°€ì ¸ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")


def main():
    """ë©”ì¸ ëŒ€ì‹œë³´ë“œ í•¨ìˆ˜"""
    st.title("ğŸ¤– Serverless RAG Assistant")
    st.caption("AWS Lambda + API Gateway + DynamoDB ê¸°ë°˜ Serverless RAG ì„œë¹„ìŠ¤")
    st.markdown("---")

    settings = render_sidebar()

    tab_chat, tab_docs = st.tabs(["ğŸ’¬ RAG Chat", "ğŸ“š ë¬¸ì„œ ê´€ë¦¬"])

    with tab_chat:
        render_query_tab(settings)

    with tab_docs:
        render_documents_tab(settings)


if __name__ == "__main__":
    main()

